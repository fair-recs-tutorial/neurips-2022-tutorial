<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Fair and Socially Responsible ML for Recommendations | NeurIPS 2022 Tutorial</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Fair and Socially Responsible ML for Recommendations" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="NeurIPS 2022 Tutorial" />
<meta property="og:description" content="NeurIPS 2022 Tutorial" />
<meta property="og:site_name" content="Fair and Socially Responsible ML for Recommendations" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Fair and Socially Responsible ML for Recommendations" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"NeurIPS 2022 Tutorial","headline":"Fair and Socially Responsible ML for Recommendations","name":"Fair and Socially Responsible ML for Recommendations","url":"/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="/">Fair and Socially Responsible ML for Recommendations</a></h1>

        

        <p>NeurIPS 2022 Tutorial</p>

        

        

        
      </header>
      <section>

      <p>Slides (available soon)</p>

<h2 id="abstract">Abstract</h2>
<p>Algorithmic rankings have become increasingly common in the online world. From social media to streaming services and from e-commerce to hiring, ranking has become the primary way online users ingest information. In many cases, recommendations have implications for both the users and items (or creators) being ranked. These systems are also increasingly personalized to viewers, relying on imperfect information to learn and respond to user preferences. In recent years, the machine learning community has become increasingly aware of potential harms to consumers (e.g. echo chambers, addictive design, virality of harmful content) and creators (e.g. access to opportunity, misattribution and appropriation). In this tutorial we will explore the current state of research on responsible recommendations and the primary challenges with designing, evaluating and training these systems for user and content providers. This tutorial additionally presents the primary challenges in applying this research in practice. The perspectives and methods presented in this tutorial will apply to recommendation systems generally and will not include any specific information regarding actual recommendation products. The tutorial is designed to be accessible to a broad audience of machine learning practitioners, some background in predictive systems and ranking is beneficial but not required.</p>

<h2 id="speakers">Speakers</h2>

<p><img src="assets/img/hannah.jpeg" alt="avatar" style="float: left; width: 100px; padding-right:20px; padding-bottom:20px" />
<a href="">Hannah Korevaar</a> is a Research Scientist at Meta on Responsible AI. Hannah got her PhD in Demography and Social Policy from Princeton. Hannah has been working on developing evaluation and mitigation strategies for recommendation systems since starting in August 2020.</p>

<p><img src="assets/img/manish.png" alt="avatar" style="float: left; width: 100px; padding-right:20px; padding-bottom:20px" /> 
<a href="https://mraghavan.github.io/">Manish Raghavan</a>, is an assistant professor at MIT in the Fall 2022. Manish got his PhD in Computer Science from Cornell University studying algorithmic fairness and its application to job search and recommendation engines, and then worked as a postdoctoral fellow at the Harvard Center for Research on Computation and Society (CRCS).</p>

<p><img src="assets/img/ashudeep.png" alt="avatar" style="float: left; width: 100px; padding-right:20px; padding-bottom:20px" />
<a href="https://www.ashudeepsingh.com/">Ashudeep Singh</a> is an Applied Research Scientist at Pinterest working on developing evaluation methods and algorithms to ensure that PInterest ML models work well for a diverse set of users and content providers. Ashudeep got his PhD in Computer Science from Cornell University studying fairness in ranking.</p>

<h2 id="panelists">Panelists</h2>

<p>Chloé Bakalar, Temple University. Chloé is Assistant Professor of Political Science. She is also a Visiting Research Collaborator at Princeton University’s Center for Information Technology Policy (CITP). She is a political and legal theorist with a background in American politics. Her work focuses on philosophical and legal questions surrounding freedom of speech, especially in relation to liberal democratic citizenship. Additional research interests include: ethics and public policy (esp. technology ethics); normative ethics; democratic theory; contemporary political thought; and the history of ideas.</p>

<p>Fernando Diaz, Google Research. Fernando Diaz is a research scientist at Google Research Montréal. Fernando’s research spans twenty years and focuses on the design of information access systems, including search engines and recommender systems. He is particularly interested in understanding and addressing the societal implications of artificial intelligence more generally. Fernando has presented his research at multiple academic conferences and served as a Program Co-Chair for the 2019 ACM Conference on Fairness, Accountability, and Transparency. Previously, Fernando was the assistant managing director of Microsoft Research Montréal, where he also led FATE Montréal, and a director of research at Spotify, where he established its research organization on recommendation, search, and personalization.</p>

<p>Diana Lam, Meta Platforms. Diana is a Data Scientist at Meta on the Responsible AI team. Diana works on evaluating recommendation systems and working to expand the user dimensions for which we can evaluate systems and models.</p>


      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>
